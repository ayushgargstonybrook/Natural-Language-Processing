{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Personal_chat_keras.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "itauzqFlbVem",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "metadata": {
        "id": "Yjr3fHBOx2cE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import nltk\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r8iBq35Rx4fa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G7RdofQGx_Dx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SZBbhOqByEdC",
        "colab_type": "code",
        "outputId": "ea6c90be-60fa-4d93-b957-1b5229d4558b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6L1P_gYabdEk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Loading Data"
      ]
    },
    {
      "metadata": {
        "id": "UWnLreWlyGer",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chats_data=pd.read_csv('/content/drive/My Drive/wcwm_chats.txt',sep=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aQN2e-lVyy6I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chats_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vSw2syT7bgKE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Processing Data"
      ]
    },
    {
      "metadata": {
        "id": "tWGd-CVVy6iO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chat = []\n",
        "chat_file = '/content/drive/My Drive/wcwm_chats.txt'\n",
        "file = open(\"/content/drive/My Drive/testfile2.txt\", 'w')\n",
        "with open(chat_file, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        if \":\" in line:\n",
        "            lineSplit = line.split(':')\n",
        "#           finalSplit = line.split(':')\n",
        "            if(len(lineSplit)>=3):\n",
        "              chat.append(lineSplit[2].lstrip())\n",
        "              file.write(lineSplit[2].lstrip())\n",
        "            else:\n",
        "              chat.append(lineSplit[1].lstrip())\n",
        "              file.write(lineSplit[1].lstrip())\n",
        "        else:\n",
        "            chat.append(line.lstrip())\n",
        "            file.write(line.lstrip())\n",
        "\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RpseYoQD1krn",
        "colab_type": "code",
        "outputId": "cfb8f684-81d3-4847-b9a6-c734dd072bd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(chat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13727"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "AC_wk2ub5cd8",
        "colab_type": "code",
        "outputId": "a25de23c-c9e3-4015-e787-e1ba260aadf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(lines)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13727"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "XNUH-qPm51Lt",
        "colab_type": "code",
        "outputId": "35e86ee2-4d0f-4b5b-bb9f-1fa33a9e2599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "chat[len(chat)-1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Okay😊'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "_ELu_iqH9QvH",
        "colab_type": "code",
        "outputId": "94b69bd3-476d-452c-b6e1-a256645fc4be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "chat[1700]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Nthng special..tu suna\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "hklCy37dbn8n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "metadata": {
        "id": "gen5kBoj-Emj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "for i,dialogue in enumerate(chat):\n",
        "  chat[i]=re.sub('[^\\w\\s]','',chat[i])\n",
        "  chat[i]=re.sub('\\n','',chat[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O2tHqymYBamz",
        "colab_type": "code",
        "outputId": "1a6a276f-a5af-4b65-8129-a74177c09b90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "chat[170]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Are m vapis aa gya ab tohostel m hu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "MixclF9BCPY5",
        "colab_type": "code",
        "outputId": "7995760c-5b25-4ba4-caad-0e0f744288d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "chat[100]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Apne lie sachn ka proposl dekh k speechlss ho gyi'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "lWuq14EICzsL",
        "colab_type": "code",
        "outputId": "f58bb884-f980-4cf9-e53a-a2084122a5a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(chat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13727"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "Yq_WQTPNDOCt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x=[]\n",
        "y=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C772VRi5bwya",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Creating Context Response Pairs"
      ]
    },
    {
      "metadata": {
        "id": "jclo3D-rCT0h",
        "colab_type": "code",
        "outputId": "77349612-8a42-4540-fec6-b1de3bafd98e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(chat)-1):\n",
        "  x.append(chat[i])\n",
        "  y.append(chat[i+1])\n",
        "print(x[:1])\n",
        "print(y[:1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Heyyakya halchal']\n",
            "['Areynaya fone ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L4Rw6ASbDA-S",
        "colab_type": "code",
        "outputId": "c63a355e-7cc3-4842-c701-64c380908c99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(x))\n",
        "print(len(y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13726\n",
            "13726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qyf4iDuvDRB0",
        "colab_type": "code",
        "outputId": "5cce8640-e2a7-461b-bd10-225823543fd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "kKFxoq9qb4An",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tokenising"
      ]
    },
    {
      "metadata": {
        "id": "bMfQLkfeDWTH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tok_x=[]\n",
        "tok_y=[]\n",
        "for i in range(len(x)):\n",
        "    tok_x.append(nltk.word_tokenize(x[i].lower()))\n",
        "    tok_y.append(nltk.word_tokenize(y[i].lower()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "00iZVH0RDdjJ",
        "colab_type": "code",
        "outputId": "be1cf150-3b3e-49b0-be40-38cc3c23a456",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "tok_x[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['heyyakya', 'halchal'],\n",
              " ['areynaya', 'fone'],\n",
              " [],\n",
              " ['konsa', 'liya'],\n",
              " ['samsung', 'galaxy', 'core', 'duos']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "Bp1UxEvI2LpY",
        "colab_type": "code",
        "outputId": "4cda4208-161c-4ef9-85d7-7535476be26b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(tok_x))\n",
        "print(len(tok_y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13726\n",
            "13726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o4eHYdZODgnf",
        "colab_type": "code",
        "outputId": "dc6cc222-209e-4945-fb2a-36a531636427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "tok_y[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['areynaya', 'fone'],\n",
              " [],\n",
              " ['konsa', 'liya'],\n",
              " ['samsung', 'galaxy', 'core', 'duos'],\n",
              " ['bhadiyaa']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "f3RQFgnn1ySK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#REMOVING EMPTY STRINGS, LISTS ETC\n",
        "# tok_x=[x for x in tok_x if x!=[]]\n",
        "# tok_y=[x for x in tok_y if x]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Iy9HilXrb-tK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Gensim Word2Vec Embeddings"
      ]
    },
    {
      "metadata": {
        "id": "BL-38u5QDjpq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=Word2Vec(tok_x+tok_y,min_count=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4ztklXhgE3A8",
        "colab_type": "code",
        "outputId": "a5fa0a3f-9394-4235-ee2e-b4fb7f624800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "cell_type": "code",
      "source": [
        "print(model[\"heyya\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.01557961e-02  1.32675134e-02 -1.22429179e-02  2.50370260e-02\n",
            "  7.32223550e-03  4.37201327e-03  2.23856028e-02  1.31591037e-02\n",
            "  1.72708072e-02 -6.24603359e-03  1.48923304e-02  1.58962756e-02\n",
            "  1.45410905e-02  2.24959361e-03 -1.04052748e-03  4.83040843e-04\n",
            " -1.94262099e-02 -8.58944934e-03  1.65967569e-02 -1.23503571e-02\n",
            " -1.68356940e-03  3.14396387e-03  8.84271413e-03 -3.45900957e-03\n",
            "  7.28650438e-03 -1.55357262e-02  4.27911786e-04  1.16850529e-02\n",
            "  1.97112653e-03 -6.71350537e-03  2.58275867e-02 -1.49169844e-02\n",
            " -5.72999986e-03 -4.02978575e-03 -9.18511022e-03 -1.08929379e-02\n",
            " -2.53186580e-02 -9.41555854e-03  4.86054644e-03  1.84114520e-02\n",
            " -1.42244445e-02 -5.04603982e-02 -3.26455012e-03  1.10240337e-02\n",
            " -1.50553966e-02 -9.24774073e-03  1.48569408e-03  8.52630532e-04\n",
            " -1.69143844e-02  3.99806537e-03 -6.44446071e-03 -1.19767906e-02\n",
            "  9.95025877e-03 -1.71556119e-02  1.28694307e-02 -3.15784849e-03\n",
            "  1.39189453e-03  1.55013716e-02 -8.83820001e-03  3.87369618e-02\n",
            " -2.79123965e-03 -1.56341167e-03  1.22293886e-02  1.78796370e-02\n",
            " -3.50286043e-03  7.03796465e-03 -3.12920660e-02 -1.02862818e-02\n",
            "  5.84421400e-03 -4.74923698e-04 -1.25916768e-02  2.29773531e-03\n",
            " -1.61937205e-03 -5.93400933e-03 -1.94721557e-02  1.86953023e-02\n",
            " -2.85116378e-02  1.11621637e-02  1.69624109e-02  1.19565136e-03\n",
            "  7.64915766e-03 -7.20433053e-03 -3.99694405e-03  1.27364369e-02\n",
            " -8.14604573e-03  4.65884060e-03 -2.49867775e-02  1.07490355e-02\n",
            " -9.75723192e-03  1.05336951e-02 -3.49856680e-03  1.04116127e-02\n",
            " -3.68919014e-03  2.13552043e-02 -9.67161264e-03 -1.93838663e-02\n",
            "  2.25933660e-02  6.64072065e-03  1.36974538e-02  8.91875388e-05]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "JtcUeVm7E5gB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vec_x=[]\n",
        "vec_y=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1xGU_tDIcC8N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sentence Embeddings"
      ]
    },
    {
      "metadata": {
        "id": "KB5n-7xhFTvp",
        "colab_type": "code",
        "outputId": "aff3b99e-8868-4135-dabf-5749b38b9625",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "for sent in tok_x:\n",
        "    sentvec=[model[w] for w in sent if w in model.wv.vocab]\n",
        "    vec_x.append(sentvec)\n",
        "for sent in tok_y:\n",
        "    sentvec=[model[w] for w in sent if w in model.wv.vocab]\n",
        "    vec_y.append(sentvec)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "6CX60FyPE_Jl",
        "colab_type": "code",
        "outputId": "61fe7f82-18f3-4d9f-b8f9-f2d3fee55f13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "vec_x[0][0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "sQE3QFWbcFdz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Padding"
      ]
    },
    {
      "metadata": {
        "id": "yuzV83wZFQNd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentend=np.ones(100,dtype=np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HD5s8F30FYhs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for tok_sent in vec_x:\n",
        "  tok_sent[14:]=[]\n",
        "  tok_sent.append(sentend)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-w16KfGGFduR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for tok_sent in vec_x:\n",
        "  if(len(tok_sent)<15):\n",
        "    for i in range(15-len(tok_sent)):\n",
        "      tok_sent.append(sentend)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-lyF1mG-Ffxk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for tok_sent in vec_y:\n",
        "  tok_sent[14:]=[]\n",
        "  tok_sent.append(sentend)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qgz75wU2HAl3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for tok_sent in vec_y:\n",
        "  if(len(tok_sent)<15):\n",
        "    for i in range(15-len(tok_sent)):\n",
        "      tok_sent.append(sentend)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bvonallOHCqM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vec_X=np.array(vec_x,dtype=np.float64)\n",
        "vec_Y=np.array(vec_y,dtype=np.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gQ14ui4eHEuP",
        "colab_type": "code",
        "outputId": "b70816f7-59b6-4332-8e4b-c080bbfbe413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "vec_X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13726, 15, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "YSeDeHqoHG_6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U scikit-learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ObHh9x9HK8o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "11OX_GiYHPcQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(vec_X,vec_Y,test_size=0.2,random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PLC2T4sTHSxs",
        "colab_type": "code",
        "outputId": "8f9efc39-f0ba-453c-e86e-5ce88bf2bab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers import Bidirectional"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ttHF3dhPHVGU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1=Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "440b3NZZHein",
        "colab_type": "code",
        "outputId": "76d5035a-8849-4283-a358-4dd41a5bc6a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10980, 15, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "metadata": {
        "id": "mjq6Z6xBcJke",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Single layer Attention Bidirectional LSTM (100 hidden Size) (BEST MODEL)"
      ]
    },
    {
      "metadata": {
        "id": "dq429Pw_HkOd",
        "colab_type": "code",
        "outputId": "7acb6a8c-0569-4053-cae1-488f25ead5c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "model1.add(Bidirectional(LSTM(100,input_shape=(15,100),return_sequences=True,init='glorot_normal',inner_init='glorot_normal',activation='tanh')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(100, input_shape=(15, 100), return_sequences=True, activation=\"tanh\", kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y9lqkTVycUWF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Attention Layer"
      ]
    },
    {
      "metadata": {
        "id": "onYDqAXxJ2Ao",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from attention_decoder import AttentionDecoder\n",
        "model1.add(AttentionDecoder(200, 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Yhy0szTH3T0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "model1.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "mc = keras.callbacks.ModelCheckpoint('weights{epoch:08d}.h5', \n",
        "                                     save_weights_only=True, period=100)\n",
        "model1.fit(x_train,y_train,nb_epoch=500,validation_data=(x_test,y_test),callbacks=[mc])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "czqLpYsEcXKV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training"
      ]
    },
    {
      "metadata": {
        "id": "Np_TrV2r5QLn",
        "colab_type": "code",
        "outputId": "ca58064d-e9c9-4309-c116-57f79dd1f005",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5868
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "model1.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "mc = keras.callbacks.ModelCheckpoint('weights{epoch:08d}.h5', \n",
        "                                     save_weights_only=True, period=169)\n",
        "model1.fit(x_train,y_train,nb_epoch=500,validation_data=(x_test,y_test),callbacks=[mc])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 10980 samples, validate on 2746 samples\n",
            "Epoch 1/500\n",
            "10980/10980 [==============================] - 63s 6ms/step - loss: 293.4336 - acc: 0.2823 - val_loss: 333.4058 - val_acc: 0.2655\n",
            "Epoch 2/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 293.5130 - acc: 0.2817 - val_loss: 330.7422 - val_acc: 0.2318\n",
            "Epoch 3/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 295.0287 - acc: 0.2826 - val_loss: 330.4751 - val_acc: 0.2663\n",
            "Epoch 4/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 295.3382 - acc: 0.2807 - val_loss: 331.6424 - val_acc: 0.2767\n",
            "Epoch 5/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 295.5690 - acc: 0.2802 - val_loss: 330.9300 - val_acc: 0.2240\n",
            "Epoch 6/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 295.0044 - acc: 0.2810 - val_loss: 333.0626 - val_acc: 0.2553\n",
            "Epoch 7/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 294.4765 - acc: 0.2816 - val_loss: 333.8941 - val_acc: 0.2442\n",
            "Epoch 8/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 293.9258 - acc: 0.2823 - val_loss: 335.8239 - val_acc: 0.2397\n",
            "Epoch 9/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 294.0031 - acc: 0.2814 - val_loss: 333.8890 - val_acc: 0.2390\n",
            "Epoch 10/500\n",
            "10980/10980 [==============================] - 57s 5ms/step - loss: 293.8505 - acc: 0.2815 - val_loss: 333.6065 - val_acc: 0.2229\n",
            "Epoch 11/500\n",
            "10980/10980 [==============================] - 57s 5ms/step - loss: 293.5014 - acc: 0.2831 - val_loss: 335.4266 - val_acc: 0.2178\n",
            "Epoch 12/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.0991 - acc: 0.2803 - val_loss: 336.4701 - val_acc: 0.2517\n",
            "Epoch 13/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 292.8918 - acc: 0.2821 - val_loss: 333.3964 - val_acc: 0.2518\n",
            "Epoch 14/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.4824 - acc: 0.2837 - val_loss: 335.5859 - val_acc: 0.2289\n",
            "Epoch 15/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.4432 - acc: 0.2837 - val_loss: 334.5589 - val_acc: 0.2603\n",
            "Epoch 16/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.2019 - acc: 0.2811 - val_loss: 333.4398 - val_acc: 0.2216\n",
            "Epoch 17/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 295.0027 - acc: 0.2787 - val_loss: 330.1840 - val_acc: 0.2283\n",
            "Epoch 18/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 294.7066 - acc: 0.2804 - val_loss: 334.0201 - val_acc: 0.2702\n",
            "Epoch 19/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 294.5400 - acc: 0.2810 - val_loss: 332.3057 - val_acc: 0.2520\n",
            "Epoch 20/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 294.0325 - acc: 0.2800 - val_loss: 330.8965 - val_acc: 0.2489\n",
            "Epoch 21/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.7461 - acc: 0.2807 - val_loss: 333.3981 - val_acc: 0.2508\n",
            "Epoch 22/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.3106 - acc: 0.2811 - val_loss: 335.1795 - val_acc: 0.2667\n",
            "Epoch 23/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 292.8745 - acc: 0.2822 - val_loss: 332.8958 - val_acc: 0.2742\n",
            "Epoch 24/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.4438 - acc: 0.2814 - val_loss: 333.3868 - val_acc: 0.2263\n",
            "Epoch 25/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.6953 - acc: 0.2773 - val_loss: 333.8739 - val_acc: 0.2138\n",
            "Epoch 26/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.9381 - acc: 0.2806 - val_loss: 334.7547 - val_acc: 0.2694\n",
            "Epoch 27/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.3309 - acc: 0.2803 - val_loss: 332.4045 - val_acc: 0.2344\n",
            "Epoch 28/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 294.2246 - acc: 0.2803 - val_loss: 333.4794 - val_acc: 0.2432\n",
            "Epoch 29/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 295.4431 - acc: 0.2771 - val_loss: 332.7077 - val_acc: 0.2303\n",
            "Epoch 30/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 294.2435 - acc: 0.2776 - val_loss: 332.0081 - val_acc: 0.2264\n",
            "Epoch 31/500\n",
            "10980/10980 [==============================] - 56s 5ms/step - loss: 294.1030 - acc: 0.2821 - val_loss: 331.1715 - val_acc: 0.2343\n",
            "Epoch 32/500\n",
            "10980/10980 [==============================] - 56s 5ms/step - loss: 293.5191 - acc: 0.2812 - val_loss: 329.1135 - val_acc: 0.2549\n",
            "Epoch 33/500\n",
            "10980/10980 [==============================] - 56s 5ms/step - loss: 295.1073 - acc: 0.2757 - val_loss: 336.5365 - val_acc: 0.1757\n",
            "Epoch 34/500\n",
            "10980/10980 [==============================] - 56s 5ms/step - loss: 299.5668 - acc: 0.2239 - val_loss: 330.4980 - val_acc: 0.2110\n",
            "Epoch 35/500\n",
            "10980/10980 [==============================] - 57s 5ms/step - loss: 294.9895 - acc: 0.2592 - val_loss: 333.7657 - val_acc: 0.2226\n",
            "Epoch 36/500\n",
            "10980/10980 [==============================] - 57s 5ms/step - loss: 294.7818 - acc: 0.2670 - val_loss: 334.3349 - val_acc: 0.2225\n",
            "Epoch 37/500\n",
            "10980/10980 [==============================] - 57s 5ms/step - loss: 295.0165 - acc: 0.2712 - val_loss: 333.2264 - val_acc: 0.2261\n",
            "Epoch 38/500\n",
            "10980/10980 [==============================] - 57s 5ms/step - loss: 293.4904 - acc: 0.2725 - val_loss: 335.0607 - val_acc: 0.2268\n",
            "Epoch 39/500\n",
            "10980/10980 [==============================] - 56s 5ms/step - loss: 292.8463 - acc: 0.2774 - val_loss: 333.1958 - val_acc: 0.2449\n",
            "Epoch 40/500\n",
            "10980/10980 [==============================] - 57s 5ms/step - loss: 292.5967 - acc: 0.2786 - val_loss: 337.0549 - val_acc: 0.2495\n",
            "Epoch 41/500\n",
            "10980/10980 [==============================] - 56s 5ms/step - loss: 293.3880 - acc: 0.2799 - val_loss: 336.7916 - val_acc: 0.2367\n",
            "Epoch 42/500\n",
            "10980/10980 [==============================] - 56s 5ms/step - loss: 292.1890 - acc: 0.2804 - val_loss: 336.4943 - val_acc: 0.2478\n",
            "Epoch 43/500\n",
            "10980/10980 [==============================] - 56s 5ms/step - loss: 292.2843 - acc: 0.2800 - val_loss: 335.3070 - val_acc: 0.2405\n",
            "Epoch 44/500\n",
            "10980/10980 [==============================] - 56s 5ms/step - loss: 292.5777 - acc: 0.2802 - val_loss: 334.5217 - val_acc: 0.2469\n",
            "Epoch 45/500\n",
            "10980/10980 [==============================] - 56s 5ms/step - loss: 292.9267 - acc: 0.2818 - val_loss: 335.2659 - val_acc: 0.2326\n",
            "Epoch 46/500\n",
            "10980/10980 [==============================] - 57s 5ms/step - loss: 293.3331 - acc: 0.2816 - val_loss: 334.3989 - val_acc: 0.2229\n",
            "Epoch 47/500\n",
            "10980/10980 [==============================] - 56s 5ms/step - loss: 293.9980 - acc: 0.2798 - val_loss: 336.3059 - val_acc: 0.2663\n",
            "Epoch 48/500\n",
            "10980/10980 [==============================] - 56s 5ms/step - loss: 292.8982 - acc: 0.2822 - val_loss: 335.7053 - val_acc: 0.2510\n",
            "Epoch 49/500\n",
            "10980/10980 [==============================] - 60s 6ms/step - loss: 294.1978 - acc: 0.2802 - val_loss: 335.0908 - val_acc: 0.2333\n",
            "Epoch 50/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 295.3084 - acc: 0.2784 - val_loss: 335.8041 - val_acc: 0.2528\n",
            "Epoch 51/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 296.6903 - acc: 0.2787 - val_loss: 332.4186 - val_acc: 0.2113\n",
            "Epoch 52/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 296.1333 - acc: 0.2792 - val_loss: 334.2976 - val_acc: 0.2360\n",
            "Epoch 53/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 294.8896 - acc: 0.2785 - val_loss: 334.0031 - val_acc: 0.2432\n",
            "Epoch 54/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.3961 - acc: 0.2793 - val_loss: 333.7591 - val_acc: 0.2207\n",
            "Epoch 55/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.6566 - acc: 0.2807 - val_loss: 334.5529 - val_acc: 0.2732\n",
            "Epoch 56/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 294.2696 - acc: 0.2790 - val_loss: 332.4174 - val_acc: 0.2447\n",
            "Epoch 57/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.5766 - acc: 0.2770 - val_loss: 333.6439 - val_acc: 0.2567\n",
            "Epoch 58/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.5448 - acc: 0.2782 - val_loss: 333.5435 - val_acc: 0.2453\n",
            "Epoch 59/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 294.2515 - acc: 0.2802 - val_loss: 329.6585 - val_acc: 0.2305\n",
            "Epoch 60/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 294.8870 - acc: 0.2791 - val_loss: 334.3251 - val_acc: 0.2336\n",
            "Epoch 61/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.8745 - acc: 0.2809 - val_loss: 336.7972 - val_acc: 0.2543\n",
            "Epoch 62/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 294.5488 - acc: 0.2792 - val_loss: 336.4469 - val_acc: 0.2510\n",
            "Epoch 63/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 293.8150 - acc: 0.2806 - val_loss: 335.3247 - val_acc: 0.2553\n",
            "Epoch 64/500\n",
            "10980/10980 [==============================] - 60s 5ms/step - loss: 293.5260 - acc: 0.2816 - val_loss: 333.9727 - val_acc: 0.2714\n",
            "Epoch 65/500\n",
            "10980/10980 [==============================] - 60s 5ms/step - loss: 293.2148 - acc: 0.2783 - val_loss: 331.3010 - val_acc: 0.1993\n",
            "Epoch 66/500\n",
            "10980/10980 [==============================] - 60s 5ms/step - loss: 293.9221 - acc: 0.2790 - val_loss: 334.0467 - val_acc: 0.2560\n",
            "Epoch 67/500\n",
            "10980/10980 [==============================] - 60s 5ms/step - loss: 292.9152 - acc: 0.2785 - val_loss: 333.5214 - val_acc: 0.2664\n",
            "Epoch 68/500\n",
            "10980/10980 [==============================] - 60s 5ms/step - loss: 293.8036 - acc: 0.2805 - val_loss: 333.1766 - val_acc: 0.2223\n",
            "Epoch 69/500\n",
            "10980/10980 [==============================] - 60s 6ms/step - loss: 294.2711 - acc: 0.2791 - val_loss: 335.0188 - val_acc: 0.2498\n",
            "Epoch 70/500\n",
            "10980/10980 [==============================] - 60s 5ms/step - loss: 294.3640 - acc: 0.2802 - val_loss: 336.3096 - val_acc: 0.2303\n",
            "Epoch 71/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 294.9794 - acc: 0.2735 - val_loss: 334.2231 - val_acc: 0.2630\n",
            "Epoch 72/500\n",
            "10980/10980 [==============================] - 60s 5ms/step - loss: 293.6676 - acc: 0.2816 - val_loss: 332.4472 - val_acc: 0.2267\n",
            "Epoch 73/500\n",
            "10980/10980 [==============================] - 60s 5ms/step - loss: 292.9860 - acc: 0.2806 - val_loss: 335.2493 - val_acc: 0.2632\n",
            "Epoch 74/500\n",
            "10980/10980 [==============================] - 60s 5ms/step - loss: 292.7668 - acc: 0.2812 - val_loss: 333.6631 - val_acc: 0.2523\n",
            "Epoch 75/500\n",
            "10980/10980 [==============================] - 60s 5ms/step - loss: 293.9603 - acc: 0.2805 - val_loss: 332.4550 - val_acc: 0.2385\n",
            "Epoch 76/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.2027 - acc: 0.2826 - val_loss: 333.4217 - val_acc: 0.2257\n",
            "Epoch 77/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 292.5933 - acc: 0.2787 - val_loss: 335.2603 - val_acc: 0.2180\n",
            "Epoch 78/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.8851 - acc: 0.2803 - val_loss: 333.1173 - val_acc: 0.2327\n",
            "Epoch 79/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.8681 - acc: 0.2818 - val_loss: 333.5439 - val_acc: 0.2189\n",
            "Epoch 80/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 294.2517 - acc: 0.2772 - val_loss: 332.6253 - val_acc: 0.2160\n",
            "Epoch 81/500\n",
            "10980/10980 [==============================] - 57s 5ms/step - loss: 293.6911 - acc: 0.2806 - val_loss: 335.8062 - val_acc: 0.2522\n",
            "Epoch 82/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 292.9343 - acc: 0.2812 - val_loss: 331.1434 - val_acc: 0.2457\n",
            "Epoch 83/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 296.2471 - acc: 0.2745 - val_loss: 332.3314 - val_acc: 0.2425\n",
            "Epoch 84/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 295.6895 - acc: 0.2763 - val_loss: 330.8005 - val_acc: 0.2503\n",
            "Epoch 85/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 295.5272 - acc: 0.2777 - val_loss: 332.3476 - val_acc: 0.2395\n",
            "Epoch 86/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.7688 - acc: 0.2801 - val_loss: 333.4534 - val_acc: 0.2262\n",
            "Epoch 87/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 292.8896 - acc: 0.2816 - val_loss: 332.8952 - val_acc: 0.2700\n",
            "Epoch 88/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 294.6843 - acc: 0.2774 - val_loss: 331.6077 - val_acc: 0.2092\n",
            "Epoch 89/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 294.9950 - acc: 0.2788 - val_loss: 331.3023 - val_acc: 0.2602\n",
            "Epoch 90/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 294.0128 - acc: 0.2790 - val_loss: 337.1105 - val_acc: 0.2403\n",
            "Epoch 91/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.5579 - acc: 0.2762 - val_loss: 334.3198 - val_acc: 0.2656\n",
            "Epoch 92/500\n",
            "10980/10980 [==============================] - 60s 5ms/step - loss: 298.5626 - acc: 0.2688 - val_loss: 334.0962 - val_acc: 0.2589\n",
            "Epoch 93/500\n",
            "10980/10980 [==============================] - 61s 6ms/step - loss: 296.6544 - acc: 0.2784 - val_loss: 331.8689 - val_acc: 0.2747\n",
            "Epoch 94/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 293.9181 - acc: 0.2793 - val_loss: 333.3146 - val_acc: 0.2509\n",
            "Epoch 95/500\n",
            "10980/10980 [==============================] - 61s 6ms/step - loss: 293.0977 - acc: 0.2815 - val_loss: 332.7409 - val_acc: 0.2597\n",
            "Epoch 96/500\n",
            "10980/10980 [==============================] - 61s 6ms/step - loss: 292.8314 - acc: 0.2786 - val_loss: 336.9392 - val_acc: 0.2308\n",
            "Epoch 97/500\n",
            "10980/10980 [==============================] - 61s 6ms/step - loss: 293.4909 - acc: 0.2798 - val_loss: 335.9011 - val_acc: 0.2583\n",
            "Epoch 98/500\n",
            "10980/10980 [==============================] - 62s 6ms/step - loss: 293.5990 - acc: 0.2802 - val_loss: 335.7765 - val_acc: 0.2549\n",
            "Epoch 99/500\n",
            "10980/10980 [==============================] - 61s 6ms/step - loss: 293.3592 - acc: 0.2818 - val_loss: 331.6214 - val_acc: 0.2291\n",
            "Epoch 100/500\n",
            "10980/10980 [==============================] - 60s 5ms/step - loss: 293.2358 - acc: 0.2784 - val_loss: 337.3513 - val_acc: 0.2693\n",
            "Epoch 101/500\n",
            "10980/10980 [==============================] - 65s 6ms/step - loss: 292.9271 - acc: 0.2801 - val_loss: 332.1994 - val_acc: 0.2666\n",
            "Epoch 102/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 292.5614 - acc: 0.2813 - val_loss: 333.1966 - val_acc: 0.2323\n",
            "Epoch 103/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 292.6042 - acc: 0.2796 - val_loss: 333.8942 - val_acc: 0.2610\n",
            "Epoch 104/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 292.7950 - acc: 0.2793 - val_loss: 333.1108 - val_acc: 0.2541\n",
            "Epoch 105/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 293.5530 - acc: 0.2781 - val_loss: 337.8087 - val_acc: 0.2381\n",
            "Epoch 106/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 293.4784 - acc: 0.2810 - val_loss: 331.0804 - val_acc: 0.2750\n",
            "Epoch 107/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 294.8925 - acc: 0.2763 - val_loss: 334.1438 - val_acc: 0.2498\n",
            "Epoch 108/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.8355 - acc: 0.2813 - val_loss: 334.2595 - val_acc: 0.2348\n",
            "Epoch 109/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 293.5714 - acc: 0.2790 - val_loss: 332.6962 - val_acc: 0.2878\n",
            "Epoch 110/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.7144 - acc: 0.2809 - val_loss: 335.0524 - val_acc: 0.2654\n",
            "Epoch 111/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 293.4660 - acc: 0.2807 - val_loss: 333.6251 - val_acc: 0.2648\n",
            "Epoch 112/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 294.9194 - acc: 0.2803 - val_loss: 332.6919 - val_acc: 0.2284\n",
            "Epoch 113/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.2799 - acc: 0.2821 - val_loss: 334.9501 - val_acc: 0.2357\n",
            "Epoch 114/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 293.3964 - acc: 0.2804 - val_loss: 331.9291 - val_acc: 0.2472\n",
            "Epoch 115/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 294.2747 - acc: 0.2789 - val_loss: 335.3832 - val_acc: 0.2724\n",
            "Epoch 116/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.1723 - acc: 0.2817 - val_loss: 334.9629 - val_acc: 0.2624\n",
            "Epoch 117/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.5314 - acc: 0.2788 - val_loss: 331.5129 - val_acc: 0.2342\n",
            "Epoch 118/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.3273 - acc: 0.2811 - val_loss: 335.4127 - val_acc: 0.2516\n",
            "Epoch 119/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 298.3334 - acc: 0.2705 - val_loss: 331.2116 - val_acc: 0.2400\n",
            "Epoch 120/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 294.6465 - acc: 0.2773 - val_loss: 335.5618 - val_acc: 0.2257\n",
            "Epoch 121/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 293.2665 - acc: 0.2813 - val_loss: 335.7134 - val_acc: 0.2761\n",
            "Epoch 122/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.6294 - acc: 0.2791 - val_loss: 333.2802 - val_acc: 0.2206\n",
            "Epoch 123/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 293.3763 - acc: 0.2778 - val_loss: 334.3269 - val_acc: 0.2362\n",
            "Epoch 124/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.7621 - acc: 0.2767 - val_loss: 334.5406 - val_acc: 0.2226\n",
            "Epoch 125/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 292.3647 - acc: 0.2812 - val_loss: 335.1969 - val_acc: 0.2255\n",
            "Epoch 126/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 291.9687 - acc: 0.2821 - val_loss: 333.3119 - val_acc: 0.2544\n",
            "Epoch 127/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 292.5937 - acc: 0.2824 - val_loss: 334.7997 - val_acc: 0.2518\n",
            "Epoch 128/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 292.4753 - acc: 0.2814 - val_loss: 335.4595 - val_acc: 0.2614\n",
            "Epoch 129/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 293.0435 - acc: 0.2772 - val_loss: 333.4062 - val_acc: 0.2701\n",
            "Epoch 130/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 293.0223 - acc: 0.2804 - val_loss: 335.3826 - val_acc: 0.2557\n",
            "Epoch 131/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 292.4173 - acc: 0.2817 - val_loss: 336.3033 - val_acc: 0.2239\n",
            "Epoch 132/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 292.4023 - acc: 0.2797 - val_loss: 334.8280 - val_acc: 0.2596\n",
            "Epoch 133/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 294.9856 - acc: 0.2592 - val_loss: 334.1967 - val_acc: 0.2241\n",
            "Epoch 134/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 295.3110 - acc: 0.2710 - val_loss: 330.9136 - val_acc: 0.2380\n",
            "Epoch 135/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 293.6882 - acc: 0.2788 - val_loss: 336.7400 - val_acc: 0.2319\n",
            "Epoch 136/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 293.4217 - acc: 0.2783 - val_loss: 332.7707 - val_acc: 0.2536\n",
            "Epoch 137/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 293.1065 - acc: 0.2807 - val_loss: 336.0812 - val_acc: 0.2672\n",
            "Epoch 138/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 293.4951 - acc: 0.2797 - val_loss: 334.2389 - val_acc: 0.2715\n",
            "Epoch 139/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 293.7381 - acc: 0.2802 - val_loss: 333.6151 - val_acc: 0.2157\n",
            "Epoch 140/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 293.8984 - acc: 0.2777 - val_loss: 332.6879 - val_acc: 0.2597\n",
            "Epoch 141/500\n",
            "10980/10980 [==============================] - 60s 5ms/step - loss: 292.8265 - acc: 0.2813 - val_loss: 333.2371 - val_acc: 0.2365\n",
            "Epoch 142/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 292.8833 - acc: 0.2792 - val_loss: 335.3121 - val_acc: 0.2471\n",
            "Epoch 143/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 294.0529 - acc: 0.2790 - val_loss: 333.9760 - val_acc: 0.2124\n",
            "Epoch 144/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 294.0390 - acc: 0.2780 - val_loss: 330.8055 - val_acc: 0.2418\n",
            "Epoch 145/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.7465 - acc: 0.2804 - val_loss: 335.8130 - val_acc: 0.2590\n",
            "Epoch 146/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 292.3853 - acc: 0.2834 - val_loss: 335.6249 - val_acc: 0.2559\n",
            "Epoch 147/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 291.7743 - acc: 0.2805 - val_loss: 336.4638 - val_acc: 0.2591\n",
            "Epoch 148/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 292.3331 - acc: 0.2812 - val_loss: 335.0546 - val_acc: 0.2315\n",
            "Epoch 149/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 292.5655 - acc: 0.2801 - val_loss: 336.0058 - val_acc: 0.2303\n",
            "Epoch 150/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.3197 - acc: 0.2787 - val_loss: 333.8500 - val_acc: 0.2444\n",
            "Epoch 151/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 292.8314 - acc: 0.2788 - val_loss: 334.2269 - val_acc: 0.2485\n",
            "Epoch 152/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.5420 - acc: 0.2782 - val_loss: 335.7342 - val_acc: 0.2422\n",
            "Epoch 153/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 296.1825 - acc: 0.2743 - val_loss: 333.2644 - val_acc: 0.2428\n",
            "Epoch 154/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 296.2440 - acc: 0.2785 - val_loss: 335.4776 - val_acc: 0.2267\n",
            "Epoch 155/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 294.2176 - acc: 0.2807 - val_loss: 333.4927 - val_acc: 0.2427\n",
            "Epoch 156/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 295.2243 - acc: 0.2796 - val_loss: 334.7935 - val_acc: 0.2249\n",
            "Epoch 157/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 293.7093 - acc: 0.2796 - val_loss: 335.1897 - val_acc: 0.2287\n",
            "Epoch 158/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 292.8875 - acc: 0.2797 - val_loss: 333.9105 - val_acc: 0.2703\n",
            "Epoch 159/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 292.7175 - acc: 0.2762 - val_loss: 332.7405 - val_acc: 0.2609\n",
            "Epoch 160/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 294.4434 - acc: 0.2766 - val_loss: 333.6178 - val_acc: 0.2278\n",
            "Epoch 161/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 295.5599 - acc: 0.2726 - val_loss: 332.5611 - val_acc: 0.2363\n",
            "Epoch 162/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 293.1460 - acc: 0.2793 - val_loss: 332.3723 - val_acc: 0.2762\n",
            "Epoch 163/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 292.6705 - acc: 0.2804 - val_loss: 332.5014 - val_acc: 0.2607\n",
            "Epoch 164/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 292.2140 - acc: 0.2787 - val_loss: 332.1305 - val_acc: 0.2294\n",
            "Epoch 165/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 292.2588 - acc: 0.2830 - val_loss: 333.1572 - val_acc: 0.2641\n",
            "Epoch 166/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.6367 - acc: 0.2803 - val_loss: 335.4230 - val_acc: 0.2591\n",
            "Epoch 167/500\n",
            "10980/10980 [==============================] - 59s 5ms/step - loss: 294.6016 - acc: 0.2750 - val_loss: 329.6221 - val_acc: 0.2563\n",
            "Epoch 168/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 295.0898 - acc: 0.2751 - val_loss: 334.1714 - val_acc: 0.2287\n",
            "Epoch 169/500\n",
            "10980/10980 [==============================] - 58s 5ms/step - loss: 293.5939 - acc: 0.2765 - val_loss: 334.4281 - val_acc: 0.2540\n",
            "Epoch 170/500\n",
            " 8352/10980 [=====================>........] - ETA: 12s - loss: 292.0080 - acc: 0.2816Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZVIkWySiJkEt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions=model1.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kNflFiYwcZrJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prediction from train Data"
      ]
    },
    {
      "metadata": {
        "id": "S003Me67026O",
        "colab_type": "code",
        "outputId": "67aab989-17f9-47ef-df8d-076f0c8d0c6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "cell_type": "code",
      "source": [
        "[model.most_similar([predictions[1000][i]])[0] for i in range(15)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('rules', 0.7248409390449524),\n",
              " ('rules', 0.7136720418930054),\n",
              " ('rules', 0.6254730820655823),\n",
              " ('84', 0.31158605217933655),\n",
              " ('84', 0.30443379282951355),\n",
              " ('ummkuchjeete', 0.2935633957386017),\n",
              " ('84', 0.2987596392631531),\n",
              " ('84', 0.29921814799308777),\n",
              " ('84', 0.2970057725906372),\n",
              " ('84', 0.2982383370399475),\n",
              " ('84', 0.29967889189720154),\n",
              " ('84', 0.2994658946990967),\n",
              " ('84', 0.2996480464935303),\n",
              " ('84', 0.30039119720458984),\n",
              " ('84', 0.30037128925323486)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "metadata": {
        "id": "9IAsl730ch2O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Chatting with the Chatbot (Prediction)"
      ]
    },
    {
      "metadata": {
        "id": "cSGctS-V4ilu",
        "colab_type": "code",
        "outputId": "34724115-f26b-4975-aab9-bb55a5afcb0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "x=\"How are you?\";\n",
        "sentend=np.ones((100,),dtype=np.float32) \n",
        "\n",
        "sent=nltk.word_tokenize(x.lower())\n",
        "sentvec = [model[w] for w in sent if w in model.wv.vocab]\n",
        "\n",
        "sentvec[14:]=[]\n",
        "sentvec.append(sentend)\n",
        "if len(sentvec)<15:\n",
        "    for i in range(15-len(sentvec)):\n",
        "        sentvec.append(sentend) \n",
        "sentvec=np.array([sentvec])\n",
        "\n",
        "predictions = model1.predict(sentvec)\n",
        "outputlist=[model.most_similar([predictions[0][i]])[0][0] for i in range(15)]\n",
        "output=' '.join(outputlist)\n",
        "print(output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "84 rules 84 ummkuchjeete 84 84 84 84 84 84 84 84 84 84 84\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zt3IU4LQ4rws",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}